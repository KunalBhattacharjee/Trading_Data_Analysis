{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Pysu-jahBT7c",
        "7PNFGqRycLkR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data parsing"
      ],
      "metadata": {
        "id": "Pysu-jahBT7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "jc2bAgjHBbks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse the files\n",
        "def parse_ASCII_file(line):\n",
        "  # Skip empty lines or without relevant data\n",
        "  if not line.strip() or 'Begin Packet' in line:\n",
        "    return None\n",
        "\n",
        "  # Extract columns using regex\n",
        "  columns={'Type':r'type=(\\d+)',\n",
        "           'ts':r'ts=(\\d+)',\n",
        "           'txTs':r'txTs=(\\d+)',\n",
        "           'OrderId':r'orderId=(\\d+)',\n",
        "           'Price':r'price=(\\d+)',\n",
        "           'Quantity':r'qty=(\\d+)',\n",
        "           'Trader':r'trader=(\\d+)',\n",
        "           'Symbol':r'symbol=(\\d+)',\n",
        "           'IsBuy':r'isBUY=(\\d+)'}\n",
        "\n",
        "  # Initialize row\n",
        "  row={}\n",
        "  for key,pattern in columns.items():\n",
        "    match=re.search(pattern,line)\n",
        "    row[key]=int(match.group(1)) if match else None\n",
        "\n",
        "  # Extract Book info if present\n",
        "  book_match=re.search(r'Book: \\[Bid: (\\d+) @ px (\\d+) \\((\\d+) orders\\) \\| Ask: qty(\\d+) @ px (\\d+) \\((\\d+) orders\\)\\]', line)\n",
        "  if book_match:\n",
        "    row['book_qty']=int(book_match.group(1))\n",
        "    row['bid_price']=int(book_match.group(2))\n",
        "    row['bid_orders']=int(book_match.group(3))\n",
        "    row['ask_qty']=int(book_match.group(4))\n",
        "    row['ask_price']=int(book_match.group(5))\n",
        "    row['ask_orders']=int(book_match.group(6))\n",
        "  else:\n",
        "    row['bid_qty']=row['bid_price']=row['bid_orders']=None\n",
        "    row['ask_qty']=row['ask_price']=row['ask_orders']=None\n",
        "\n",
        "  return row"
      ],
      "metadata": {
        "id": "N2LhxU1LBuax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydo1NXlMHN6w",
        "outputId": "fd25e5a7-ca2f-4738-a564-fe0e510566d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the work directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "-Jx2s1LTHW7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and parse file lines. Starting with Rainbow file.\n",
        "with open ('JumpTradingInterview-MarketData-ASCII.RAINBOW.txt', 'r', encoding='ASCII') as f:\n",
        "  lines=f.readlines()\n",
        "\n",
        "# Parse lines into a list of dictionaries  and remove none entries\n",
        "data=[parse_ASCII_file(line) for line in lines]\n",
        "data=[d for d in data if d is not None]\n",
        "\n",
        "# Create a DataFrame\n",
        "market_data_df=pd.DataFrame(data)\n",
        "\n",
        "# Filtering for only add events for now\n",
        "market_data_df=market_data_df[market_data_df['type']==1]\n",
        "\n",
        "# Saving to the location\n",
        "market_data_df.to_csv('JumpTradingInterview-MD_RAINBOW.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Fpmho5I6HbBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing the same for Unicorn file.\n",
        "with open ('JumpTradingInterview-MarketData-ASCII.UNICORN.txt', 'r', encoding='ASCII') as f:\n",
        "  lines=f.readlines()\n",
        "\n",
        "# Parse lines into a list of dictionaries  and remove none entries\n",
        "data=[parse_ASCII_file(line) for line in lines]\n",
        "data=[d for d in data if d is not None]\n",
        "\n",
        "# Create a DataFrame\n",
        "market_data_df=pd.DataFrame(data)\n",
        "\n",
        "# Filtering for only add events for now\n",
        "market_data_df=market_data_df[market_data_df['type']==1]\n",
        "\n",
        "# Saving to the location\n",
        "market_data_df.to_csv('JumpTradingInterview-MD_UNICORN.csv', index=False)\n"
      ],
      "metadata": {
        "id": "szprdOMNXyTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep and Combining the 2 Files"
      ],
      "metadata": {
        "id": "7PNFGqRycLkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 2 files and Concatenate\n",
        "md_rainbow_df=pd.read_csv('JumpTradingInterview-MD_RAINBOW.csv')\n",
        "md_unicorn_df=pd.read_csv('JumpTradingInterview-MD_UNICORN.csv')\n",
        "\n",
        "market_data_df=pd.DataFrame() #Reassigning it as an empty DataFrame\n",
        "market_data_df=pd.concat([md_rainbow_df, md_unicorn_df])"
      ],
      "metadata": {
        "id": "7hpCf4OGcbr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert time format to relevant timestamp to match the fill report files\n",
        "market_data_df['ts']=pd.to_datetime(market_data_df['ts'], unit='ns') # Using the same unit as in for the Fill reports\n",
        "market_data_df['txTs']=pd.to_datetime(market_data_df['txTs'], unit='ns')"
      ],
      "metadata": {
        "id": "OvNiF6TER2CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map Symbols\n",
        "'''\n",
        "These files use numbers to deonote the symbols while the fill files use names.\n",
        "Mapping the numbers to names on the basis of followign logic.\n",
        "Since RAINBOWZ0 is more active, so whichever is more will be assigned that and other will be assigned\n",
        "UNICORNZ0.\n",
        "'''\n",
        "market_data_df['symbol']=market_data_df['symbol'].map({1:'RAINBOWZ0', 2:'UNICORNZ0'})"
      ],
      "metadata": {
        "id": "KqwMDicsTVv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving it into a new CSV\n",
        "market_data_df.to_csv('MD-Combined.csv', index=False)"
      ],
      "metadata": {
        "id": "QQad34CreH-4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}